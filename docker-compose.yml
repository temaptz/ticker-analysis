services:
  tasks:
    build:
      context: .
      dockerfile: Dockerfile-python-services
    container_name: tasks
    volumes:
      - /etc/is_my_prod:/container_host_is_prod:ro
      - ./learn_models:/app/learn_models
    command:
      - python
      - main.py
    depends_on:
      - redis
      - postgres
    restart: unless-stopped

  learn:
    build:
      context: .
      dockerfile: Dockerfile-python-services
    container_name: learn
    volumes:
      - /etc/is_my_prod:/container_host_is_prod:ro
      - ./learn_models:/app/learn_models
    command:
      - python
      - learn.py
    depends_on:
      - redis
      - postgres
    restart: no

  news_rate:
    build:
      context: .
      dockerfile: Dockerfile-python-services
    container_name: news_rate
    volumes:
      - /etc/is_my_prod:/container_host_is_prod:ro
      - ./learn_models:/app/learn_models
    command:
      - python
      - news_rate.py
    depends_on:
      - redis
      - postgres
      - ollama
    restart: no

  apiserver:
    build:
      context: .
      dockerfile: Dockerfile-python-services
    container_name: apiserver
    volumes:
      - /etc/is_my_prod:/container_host_is_prod:ro
      - ./learn_models:/app/learn_models
#    ports:
#      - "8000:8000"
    command: >
      gunicorn apiserver.wsgi:application
      --chdir /app/apiserver
      --bind 0.0.0.0:8000
      --worker-class gthread
      --workers 4
      --threads 16
      --timeout 120
    depends_on:
      - redis
      - postgres
    restart: unless-stopped

#  local_llm:
#    build:
#      context: .
#      dockerfile: ./local_llm/Dockerfile
#    container_name: local_llm
#    volumes:
#      - ./local_llm/models_cache:/app/models_cache
#    restart: no
#    ports:
#      - "8090:8090"

  ollama:
    image: ollama/ollama:latest      # официальный образ
    container_name: ollama
    ports:
      - "11434:11434"               # API наружу
    volumes:
      - ollama_data:/root/.ollama   # постоянное хранилище моделей
    environment:
      - OLLAMA_HOST=0.0.0.0:11434   # слушать на всех интерфейсах
      - OLLAMA_KEEP_ALIVE=1h       # держать модель в памяти 1h
    restart: unless-stopped

  ui:
    build:
      context: ./ui
      dockerfile: Dockerfile
    container_name: ui
    ports:
      - "80:80"
    depends_on:
      - apiserver
      - pgadmin
    restart: unless-stopped

  postgres:
    image: postgres:alpine  # или другая стабильная версия PostgreSQL
    container_name: postgres
    volumes:
      - pg_data:/var/lib/postgresql/data
#    ports:
#      - "5432:5432"   # проброс порта для локального доступа (необязательно)
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    healthcheck:
      test: sh -c 'pg_isready -U "$POSTGRES_USER" -d "$POSTGRES_DB"'
      interval: 5s
      timeout: 5s
      retries: 5
    command: postgres -c max_connections=256
    restart: unless-stopped

  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: temaptz@gmail.com
      PGADMIN_DEFAULT_PASSWORD: admin
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    restart: unless-stopped

  redis:
    image: redis:alpine
    container_name: redis
    command: ["redis-server", "/usr/local/etc/redis/redis.conf"]
    volumes:
      - redis_data:/data
      - ./redis.conf:/usr/local/etc/redis/redis.conf
#    ports:
#      - "6379:6379"
    restart: unless-stopped

volumes:
  pg_data:
  pgadmin_data:
  redis_data:
  ollama_data:
