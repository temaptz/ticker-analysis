services:
  tasks:
    build:
      context: .
      dockerfile: Dockerfile-python-services
    container_name: tasks
    volumes:
      - /etc/is_my_prod:/container_host_is_prod:ro
      - ./learn_models:/app/learn_models
    command:
      - python
      - main.py
    depends_on:
      - redis
      - postgres
      - ollama
    environment:
      - OLLAMA_MODEL_NAME=${OLLAMA_MODEL_NAME}
    restart: unless-stopped

  learn:
    build:
      context: .
      dockerfile: Dockerfile-python-services
    container_name: learn
    volumes:
      - /etc/is_my_prod:/container_host_is_prod:ro
      - ./learn_models:/app/learn_models
    command:
      - python
      - learn.py
    depends_on:
      - redis
      - postgres
      - ollama
    restart: no

  predict:
    build:
      context: .
      dockerfile: Dockerfile-python-services
    container_name: predict
    volumes:
      - /etc/is_my_prod:/container_host_is_prod:ro
      - ./learn_models:/app/learn_models
    command:
      - python
      - cache_predictions.py
    depends_on:
      - redis
      - postgres
    restart: no

  apiserver:
    build:
      context: .
      dockerfile: Dockerfile-python-services
    container_name: apiserver
    volumes:
      - /etc/is_my_prod:/container_host_is_prod:ro
      - ./learn_models:/app/learn_models
#    ports:
#      - "8000:8000"
    command: >
      uvicorn fast_api:app
      --host 0.0.0.0
      --port 8000
      --workers 6
      --loop uvloop
      --timeout-keep-alive 5
      --limit-concurrency 50
      --backlog 4096

    depends_on:
      - redis
      - postgres
    environment:
      - OLLAMA_MODEL_NAME=${OLLAMA_MODEL_NAME}
    restart: unless-stopped

  ui:
    build:
      context: ./ui
      dockerfile: Dockerfile
    container_name: ui
    ports:
      - "8081:80"
    depends_on:
      - apiserver
      - pgadmin
    restart: unless-stopped

  ollama:
    build:
      context: .
      dockerfile: Dockerfile-ollama
    container_name: ollama
#    ports:
#      - "11434:11434"               # API наружу
    volumes:
      - ollama_data:/root/.ollama   # постоянное хранилище моделей
    environment:
      - OLLAMA_HOST=0.0.0.0:11434   # слушать на всех интерфейсах
      - OLLAMA_KEEP_ALIVE=1h       # держать модель в памяти 1h
      - MODEL_NAME=${OLLAMA_MODEL_NAME}
    healthcheck:
      test: ["CMD-SHELL", "OLLAMA_HOST=127.0.0.1:11434 ollama list >/dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 12
    restart: unless-stopped

  postgres:
    image: postgres:alpine  # или другая стабильная версия PostgreSQL
    container_name: postgres
    volumes:
      - pg_data:/var/lib/postgresql/data
#    ports:
#      - "5432:5432"
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    healthcheck:
      test: sh -c 'pg_isready -U "$POSTGRES_USER" -d "$POSTGRES_DB"'
      interval: 5s
      timeout: 5s
      retries: 5
    command: postgres -c max_connections=256
    restart: unless-stopped

  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: temaptz@gmail.com
      PGADMIN_DEFAULT_PASSWORD: admin
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    restart: unless-stopped

  redis:
    image: redis:alpine
    container_name: redis
    command: ["redis-server", "/usr/local/etc/redis/redis.conf"]
    volumes:
      - redis_data:/data
      - ./redis.conf:/usr/local/etc/redis/redis.conf
#    ports:
#     - "6379:6379"
    restart: unless-stopped

volumes:
  pg_data:
  pgadmin_data:
  redis_data:
  ollama_data:
  n8n_data:
